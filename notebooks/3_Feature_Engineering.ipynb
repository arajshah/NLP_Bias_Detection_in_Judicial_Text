{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (76538, 16)\n",
      "Sample rows:\n",
      "\n",
      "Data Types:\n",
      "AGE         float64\n",
      "NEWRACE      object\n",
      "MONSEX       object\n",
      "EDUCATN      object\n",
      "DISTRICT     object\n",
      "CIRCDIST     object\n",
      "CRIMHIST     object\n",
      "SENTYR      float64\n",
      "CITIZEN      object\n",
      "CITWHERE     object\n",
      "NUMDEPEN     object\n",
      "CRIMLIV      object\n",
      "SENTMON      object\n",
      "ZONE         object\n",
      "DISPOSIT     object\n",
      "SENTTOT     float64\n",
      "dtype: object\n",
      "\n",
      "Unique values in NEWRACE:\n",
      "['Hispanic' 'White' 'Black' 'Other' 'American Indian or Alaskan Native'\n",
      " 'Asian or Pacific Islander' nan]\n",
      "\n",
      "Unique values in MONSEX:\n",
      "['Male' 'Female' nan]\n",
      "\n",
      "Unique values in EDUCATN:\n",
      "['Six years of school completed' 'High school graduate'\n",
      " 'Some trade or vocational school' 'Nine years of school completed'\n",
      " 'Some college' 'College graduate' 'Eleven years of school completed'\n",
      " 'G.E.D. (general education diploma)' nan 'One year of school completed'\n",
      " 'Trade or vocational degree' 'Middle school / junior high'\n",
      " 'Ten years of school completed' 'Four years of school completed'\n",
      " 'Some high school' 'Associate degree (A.A.)'\n",
      " 'Eight years of school completed'\n",
      " 'Graduate degree (MST, J.D., M.D., PH.D., etc)'\n",
      " 'Seven years of school completed' 'Three years of school completed'\n",
      " 'Two years of school completed' 'Five years of school completed'\n",
      " 'No schooling' 'Some elementary school' 'Military training'\n",
      " 'One year of college / freshman' 'Two years of college / sophomore'\n",
      " 'Three years of college / junior' 'Some graduate school']\n",
      "\n",
      "Unique values in CITIZEN:\n",
      "['Illegal alien' 'United States citizen' 'Resident/legal alien'\n",
      " 'Not a US citizen/alien status unknown' nan 'Extradited Alien']\n",
      "\n",
      "Unique values in ZONE:\n",
      "['Zone D' 'Zone A' nan 'Zone B' 'Zone C']\n",
      "\n",
      "Unique values in SENTMON:\n",
      "['October' 'November' 'December' 'January' 'February' 'March' 'April'\n",
      " 'May' 'June' 'July' 'August' 'September']\n",
      "\n",
      "Unique values in DISPOSIT:\n",
      "['Guilty plea' 'Jury trial' 'Nolo contendere'\n",
      " 'Trial by judge or bench trial' 'Guilty plea and trial (>1count)']\n",
      "\n",
      "Intermediate dataset saved to: cleaned_data_after_subphase_3_1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ussc_df = pd.read_csv('../data/cleaned_data_phase2.csv')\n",
    "\n",
    "# Step 1: Confirm Data Integrity\n",
    "print(\"Dataset shape:\", ussc_df.shape)\n",
    "print(\"Sample rows:\")\n",
    "# print(ussc_df.head())\n",
    "\n",
    "# Step 2: Remove Duplicates\n",
    "before_dups = ussc_df.shape[0]\n",
    "ussc_df.drop_duplicates(inplace=True)\n",
    "after_dups = ussc_df.shape[0]\n",
    "# print(f\"Dropped {before_dups - after_dups} duplicate rows.\")\n",
    "\n",
    "# Step 3: Check Data Types\n",
    "print(\"\\nData Types:\")\n",
    "print(ussc_df.dtypes)\n",
    "\n",
    "# Step 4: Validate Unique Values in Key Categorical Features\n",
    "categorical_features = ['NEWRACE', 'MONSEX', 'EDUCATN', 'CITIZEN', 'ZONE', \"SENTMON\", \"DISPOSIT\"]\n",
    "for feature in categorical_features:\n",
    "    print(f\"\\nUnique values in {feature}:\")\n",
    "    print(ussc_df[feature].unique())\n",
    "\n",
    "# Step 5: Check for Missing Data\n",
    "missing_counts = ussc_df.isna().sum().sort_values(ascending=False)\n",
    "# print(\"\\nMissing Values per Feature:\")\n",
    "# print(missing_counts)\n",
    "\n",
    "# Step 6: Save the Cleaned Dataset After Sub-Phase 3.1\n",
    "# This ensures we can revisit this intermediate state if needed\n",
    "output_file = \"cleaned_data_after_subphase_3_1.csv\"\n",
    "ussc_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nIntermediate dataset saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values per Feature:\n",
      "AGE           44\n",
      "NEWRACE      794\n",
      "MONSEX       104\n",
      "EDUCATN     8296\n",
      "DISTRICT       0\n",
      "CIRCDIST       0\n",
      "CRIMHIST    1968\n",
      "SENTYR         0\n",
      "CITIZEN      415\n",
      "CITWHERE    1352\n",
      "NUMDEPEN    8317\n",
      "CRIMLIV     4994\n",
      "SENTMON        0\n",
      "ZONE        1145\n",
      "DISPOSIT       0\n",
      "SENTTOT     6336\n",
      "dtype: int64\n",
      "count    76314.000000\n",
      "mean       207.880397\n",
      "std        543.185412\n",
      "min          0.030000\n",
      "25%          6.000000\n",
      "50%         24.000000\n",
      "75%         80.000000\n",
      "max       2000.000000\n",
      "Name: SENTTOT, dtype: float64\n",
      "\n",
      "Data Types:\n",
      "AGE         float64\n",
      "NEWRACE      object\n",
      "MONSEX       object\n",
      "EDUCATN      object\n",
      "DISTRICT     object\n",
      "CIRCDIST     object\n",
      "CRIMHIST      int64\n",
      "SENTYR      float64\n",
      "CITIZEN      object\n",
      "CITWHERE     object\n",
      "NUMDEPEN    float64\n",
      "CRIMLIV      object\n",
      "SENTMON      object\n",
      "ZONE         object\n",
      "DISPOSIT     object\n",
      "SENTTOT     float64\n",
      "dtype: object\n",
      "Filled missing values in AGE with median: 35.0\n",
      "Filled missing values in NUMDEPEN with median: 1.0\n",
      "Filled missing values in CRIMHIST with median: 1.0\n",
      "Filled missing values in SENTYR with median: 2019.0\n",
      "Filled missing values in SENTTOT with median: 24.0\n",
      "\n",
      "Missing Values After Handling:\n",
      "AGE         0\n",
      "NEWRACE     0\n",
      "MONSEX      0\n",
      "EDUCATN     0\n",
      "DISTRICT    0\n",
      "CIRCDIST    0\n",
      "CRIMHIST    0\n",
      "SENTYR      0\n",
      "CITIZEN     0\n",
      "CITWHERE    0\n",
      "NUMDEPEN    0\n",
      "CRIMLIV     0\n",
      "SENTMON     0\n",
      "ZONE        0\n",
      "DISPOSIT    0\n",
      "SENTTOT     0\n",
      "dtype: int64\n",
      "0\n",
      "\n",
      "Dataset after handling missing values saved to: cleaned_data_after_subphase_3_2.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the intermediate dataset from Sub-Phase 3.1\n",
    "file_path = \"cleaned_data_after_subphase_3_1.csv\"\n",
    "ussc_df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 1: Check for Missing Values Again\n",
    "missing_counts = ussc_df.isna().sum()\n",
    "print(\"\\nMissing Values per Feature:\")\n",
    "print(missing_counts)\n",
    "\n",
    "# Step 2: Preprocessing Specific Features\n",
    "# Convert \"No Dependents\" in NUMDEPEN to 0 and ensure numeric type\n",
    "ussc_df['NUMDEPEN'] = ussc_df['NUMDEPEN'].replace(\"No dependents\", 0).astype(float)\n",
    "\n",
    "# Convert CRIMHIST to binary values: 1 for \"Yes, there is a criminal history\", 0 otherwise\n",
    "ussc_df['CRIMHIST'] = ussc_df['CRIMHIST'].apply(lambda x: 1 if x == \"Yes, there is a criminal history\" else 0)\n",
    "\n",
    "# Remove extreme outliers in SENTOT\n",
    "ussc_df['SENTTOT'] = ussc_df['SENTTOT'].apply(lambda x: x if x < 2000 else 2000)\n",
    "print(ussc_df[\"SENTTOT\"].describe())\n",
    "\n",
    "print(\"\\nData Types:\")\n",
    "print(ussc_df.dtypes)\n",
    "\n",
    "# Step 3: Handling Missing Values\n",
    "# Define strategies for missing data\n",
    "# Numerical Features: Fill with median\n",
    "numerical_features = ['AGE', 'NUMDEPEN', 'CRIMHIST', 'SENTYR', \"SENTTOT\"]\n",
    "for feature in numerical_features:\n",
    "    median_value = ussc_df[feature].median()\n",
    "    ussc_df.fillna({feature: median_value}, inplace=True)\n",
    "    print(f\"Filled missing values in {feature} with median: {median_value}\")\n",
    "\n",
    "# Categorical Features: Fill with \"Unknown\"\n",
    "categorical_features = ['NEWRACE', 'MONSEX', 'EDUCATN', 'CITIZEN', 'CITWHERE', 'ZONE', 'DISTRICT', 'CIRCDIST', 'CRIMLIV', 'SENTMON']\n",
    "for feature in categorical_features:\n",
    "    ussc_df.fillna({feature : \"Unknown\"}, inplace=True)\n",
    "    # print(f\"Filled missing values in {feature} with 'Unknown'\")\n",
    "\n",
    "# Step 3: Validate No Missing Values Remain\n",
    "missing_counts_after = ussc_df.isna().sum()\n",
    "print(\"\\nMissing Values After Handling:\")\n",
    "print(missing_counts_after)\n",
    "print(ussc_df[\"AGE\"].isna().sum())\n",
    "\n",
    "# Step 4: Save the Dataset After Handling Missing Values\n",
    "output_file = \"cleaned_data_after_subphase_3_2.csv\"\n",
    "ussc_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nDataset after handling missing values saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial checks on AGE:\n",
      "Missing in AGE: 0\n",
      "AGE describe:\n",
      " count    76314.000000\n",
      "mean        36.394633\n",
      "std         10.935215\n",
      "min         16.000000\n",
      "25%         28.000000\n",
      "50%         35.000000\n",
      "75%         43.000000\n",
      "max         86.000000\n",
      "Name: AGE, dtype: float64\n",
      "Created 'AGE_BIN' feature. Unique bins:\n",
      " AGE_BIN\n",
      "25-35    27526\n",
      "35-45    22707\n",
      "45+      16320\n",
      "<25       9761\n",
      "Name: count, dtype: int64\n",
      "Standardized numerical features (including AGE).\n",
      "Created 'RACE_CITIZEN' feature.\n",
      "\n",
      "Describe disposit\n",
      "AGE              float64\n",
      "NEWRACE           object\n",
      "MONSEX            object\n",
      "EDUCATN           object\n",
      "DISTRICT          object\n",
      "CIRCDIST          object\n",
      "CRIMHIST         float64\n",
      "SENTYR           float64\n",
      "CITIZEN           object\n",
      "CITWHERE          object\n",
      "NUMDEPEN         float64\n",
      "CRIMLIV           object\n",
      "SENTMON           object\n",
      "ZONE              object\n",
      "DISPOSIT          object\n",
      "SENTTOT          float64\n",
      "AGE_BIN         category\n",
      "RACE_CITIZEN      object\n",
      "dtype: object\n",
      "DISPOSIT\n",
      "Guilty plea                        74416\n",
      "Jury trial                          1742\n",
      "Nolo contendere                       70\n",
      "Trial by judge or bench trial         63\n",
      "Guilty plea and trial (>1count)       23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Applied one-hot encoding to categorical features.\n",
      "\n",
      "Missing Values After Handling:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Check AGE_BIN distribution (no NaNs expected):\n",
      "AGE_BIN\n",
      "25-35    27526\n",
      "35-45    22707\n",
      "45+      16320\n",
      "<25       9761\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. Load and Inspect the Dataset\n",
    "# --------------------------------------------------\n",
    "file_path = \"cleaned_data_after_subphase_3_2.csv\"\n",
    "ussc_df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Initial checks on AGE:\")\n",
    "print(\"Missing in AGE:\", ussc_df[\"AGE\"].isna().sum())\n",
    "print(\"AGE describe:\\n\", ussc_df['AGE'].describe())\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. Bin AGE Before Scaling\n",
    "# --------------------------------------------------\n",
    "# Define age bins based on actual age values\n",
    "age_bins = [0, 25, 35, 45, np.inf]\n",
    "age_labels = ['<25', '25-35', '35-45', '45+']\n",
    "\n",
    "# Create 'AGE_BIN' from the raw (unscaled) AGE\n",
    "ussc_df['AGE_BIN'] = pd.cut(\n",
    "    ussc_df['AGE'],\n",
    "    bins=age_bins,\n",
    "    labels=age_labels,\n",
    "    right=False,       # intervals like [0,25), [25,35), etc.\n",
    "    include_lowest=True\n",
    ")\n",
    "print(\"Created 'AGE_BIN' feature. Unique bins:\\n\", ussc_df[\"AGE_BIN\"].value_counts(dropna=False))\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. Standardize Other Numeric Features\n",
    "#    Exclude 'AGE' from scaling if you want to preserve the raw age in the dataset\n",
    "# --------------------------------------------------\n",
    "# If you still want to scale AGE for some analysis, store the raw in another column:\n",
    "# ussc_df['AGE_RAW'] = ussc_df['AGE']\n",
    "# Then scale 'AGE'\n",
    "numerical_features = ['AGE', 'NUMDEPEN', 'CRIMHIST', 'SENTYR', \"SENTTOT\"]\n",
    "scaler = StandardScaler()\n",
    "ussc_df[numerical_features] = scaler.fit_transform(ussc_df[numerical_features])\n",
    "print(\"Standardized numerical features (including AGE).\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. Create Interaction Features\n",
    "# --------------------------------------------------\n",
    "# Example: Race + Citizenship\n",
    "ussc_df['RACE_CITIZEN'] = ussc_df['NEWRACE'] + \"_\" + ussc_df['CITIZEN']\n",
    "print(\"Created 'RACE_CITIZEN' feature.\")\n",
    "\n",
    "print(\"\\nDescribe disposit\")\n",
    "print(ussc_df.dtypes)\n",
    "print(ussc_df[\"DISPOSIT\"].value_counts(dropna=False))\n",
    "\n",
    "ussc_df.to_csv(\"../data/cleaned_data_phase3_unencoded_DISPOSIT.csv\", index=False)\n",
    "ussc_df.drop(columns=['DISPOSIT', \"SENTTOT\"], inplace=True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. Encode Categorical Features\n",
    "# --------------------------------------------------\n",
    "categorical_features = [\n",
    "    'NEWRACE', 'MONSEX', 'EDUCATN',\n",
    "    'CITIZEN', 'CITWHERE', 'ZONE', 'DISTRICT',\n",
    "    'CIRCDIST', 'CRIMLIV', 'AGE_BIN', 'RACE_CITIZEN', 'SENTMON'\n",
    "]\n",
    "\n",
    "encoded_df = pd.get_dummies(ussc_df, columns=categorical_features, drop_first=True)\n",
    "print(\"\\nApplied one-hot encoding to categorical features.\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6. Final Verification\n",
    "# --------------------------------------------------\n",
    "missing_counts_final = encoded_df.isna().sum()\n",
    "print(\"\\nMissing Values After Handling:\")\n",
    "print(missing_counts_final[missing_counts_final > 0])\n",
    "\n",
    "print(\"\\nCheck AGE_BIN distribution (no NaNs expected):\")\n",
    "print(ussc_df[\"AGE_BIN\"].value_counts(dropna=False))\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # 7. Save the Transformed Dataset\n",
    "# # --------------------------------------------------\n",
    "# output_file = \"../data/cleaned_data_phase3.csv\"\n",
    "# encoded_df.to_csv(output_file, index=False)\n",
    "# print(f\"\\nDataset after feature transformation saved to: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
