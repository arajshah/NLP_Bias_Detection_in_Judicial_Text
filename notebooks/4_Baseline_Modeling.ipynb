{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUB-PHASE 4.1: DATA LOAD & TARGET PREP ===\n",
      "Features dataset loaded: (76314, 433) shape\n",
      "Original target dataset loaded: (76314, 18) shape\n",
      "Final merged dataset: (76314, 435) shape\n",
      "\n",
      "Quick checks on merged data:\n",
      "        AGE  CRIMHIST    SENTYR  NUMDEPEN  NEWRACE_Asian or Pacific Islander  \\\n",
      "0 -0.218985  0.400021 -1.803579  0.263778                              False   \n",
      "1 -0.036088  0.400021 -1.803579  0.263778                              False   \n",
      "2  1.244187  0.400021 -1.803579 -0.330798                              False   \n",
      "\n",
      "   NEWRACE_Black  NEWRACE_Hispanic  NEWRACE_Other  NEWRACE_Unknown  \\\n",
      "0          False              True          False            False   \n",
      "1          False              True          False            False   \n",
      "2          False              True          False            False   \n",
      "\n",
      "   NEWRACE_White  ...  SENTMON_January  SENTMON_July  SENTMON_June  \\\n",
      "0          False  ...            False         False         False   \n",
      "1          False  ...            False         False         False   \n",
      "2          False  ...            False         False         False   \n",
      "\n",
      "   SENTMON_March  SENTMON_May  SENTMON_November  SENTMON_October  \\\n",
      "0          False        False             False             True   \n",
      "1          False        False             False             True   \n",
      "2          False        False             False             True   \n",
      "\n",
      "   SENTMON_September     DISPOSIT   SENTTOT  \n",
      "0              False  Guilty plea -0.327479  \n",
      "1              False  Guilty plea -0.378971  \n",
      "2              False  Guilty plea -0.349571  \n",
      "\n",
      "[3 rows x 435 columns]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# PHASE 4: BASELINE MODELING\n",
    "################################################################################\n",
    "\n",
    "###############################\n",
    "#        IMPORTS & SETUP\n",
    "###############################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing & Splits\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Models for Classification & Regression\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "###############################\n",
    "#   SUB-PHASE 4.1: DATA LOAD\n",
    "#          & TARGET PREP\n",
    "###############################\n",
    "print(\"=== SUB-PHASE 4.1: DATA LOAD & TARGET PREP ===\")\n",
    "\n",
    "# 1. Load Feature-Engineered Dataset (PHASE 3 Output)\n",
    "feature_file = \"../data/cleaned_data_phase3.csv\"\n",
    "encoded_features_df = pd.read_csv(feature_file)\n",
    "print(f\"Features dataset loaded: {encoded_features_df.shape} shape\")\n",
    "\n",
    "# 2. Load Original Columns (DISPOSIT, SENTTOT)\n",
    "original_file = \"../data/cleaned_data_phase3_unencoded_DISPOSIT.csv\"\n",
    "original_df = pd.read_csv(original_file)\n",
    "print(f\"Original target dataset loaded: {original_df.shape} shape\")\n",
    "\n",
    "# 3. Merge to Form final_df\n",
    "#    Ensures we have both feature-engineered columns + original DISPOSIT & SENTTOT\n",
    "final_df = encoded_features_df.join(original_df[['DISPOSIT', 'SENTTOT']])\n",
    "print(f\"Final merged dataset: {final_df.shape} shape\")\n",
    "\n",
    "# 4. Quick Checks\n",
    "print(\"\\nQuick checks on merged data:\")\n",
    "print(final_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUB-PHASE 4.2: ENCODE TARGETS & DATA SPLITS ===\n",
      "\n",
      "--- Classification Target: DISPOSIT ---\n",
      "\n",
      "Binary DISPOSIT distribution:\n",
      "DISPOSIT_BINARY\n",
      "0    74486\n",
      "1     1828\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feature matrix shape: (76314, 433)\n",
      "Binary target vector shape: (76314, 2)\n",
      "\n",
      "Train set shape: (61051, 433) y_train: (61051,)\n",
      "Test set shape: (15263, 433) y_test: (15263,)\n",
      "\n",
      "Binary DISPOSIT Distribution in Train set:\n",
      "DISPOSIT_BINARY\n",
      "0    0.976053\n",
      "1    0.023947\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Binary DISPOSIT Distribution in Test set:\n",
      "DISPOSIT_BINARY\n",
      "0    0.97602\n",
      "1    0.02398\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "#   SUB-PHASE 4.2: ENCODE TARGETS \n",
    "#         & DATA SPLITS\n",
    "###############################\n",
    "print(\"\\n=== SUB-PHASE 4.2: ENCODE TARGETS & DATA SPLITS ===\")\n",
    "\n",
    "# --- 4.2.1: DISPOSIT as Classification Target ---\n",
    "print(\"\\n--- Classification Target: DISPOSIT ---\")\n",
    "\n",
    "# Step 1: Create Binary DISPOSIT\n",
    "def binary_disposit(disposit):\n",
    "    if disposit in ['Jury trial', 'Trial by judge or bench trial', 'Guilty plea and trial (>1count)']:\n",
    "        return 1  # Went to Trial\n",
    "    elif disposit in ['Guilty plea', 'Nolo contendere']:\n",
    "        return 0  # Did Not Go to Trial\n",
    "    else:\n",
    "        return 0  # Default to 0 if unexpected category\n",
    "\n",
    "final_df['DISPOSIT_BINARY'] = final_df['DISPOSIT'].apply(binary_disposit)\n",
    "print(\"\\nBinary DISPOSIT distribution:\")\n",
    "print(final_df['DISPOSIT_BINARY'].value_counts())\n",
    "\n",
    "# Step 2: Define Feature Matrix X and Binary Target y\n",
    "X_classif = final_df.drop(columns=['DISPOSIT', 'SENTTOT', 'DISPOSIT_BINARY'])\n",
    "y_classif = final_df['DISPOSIT_BINARY']\n",
    "\n",
    "print(\"\\nFeature matrix shape:\", X.shape)\n",
    "print(\"Binary target vector shape:\", y.shape)\n",
    "\n",
    "# Step 3: Perform Train/Test Split with Stratification\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_classif, y_classif,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_classif  # Maintains the distribution of classes\n",
    ")\n",
    "\n",
    "print(\"\\nTrain set shape:\", X_train_c.shape, \"y_train:\", y_train_c.shape)\n",
    "print(\"Test set shape:\", X_test_c.shape, \"y_test:\", y_test_c.shape)\n",
    "\n",
    "# Step 4: Verify the Split\n",
    "print(\"\\nBinary DISPOSIT Distribution in Train set:\")\n",
    "print(y_train_c.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nBinary DISPOSIT Distribution in Test set:\")\n",
    "print(y_test_c.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Regression Target: SENTTOT ---\n",
      "\n",
      "Regression splits:\n",
      "X_train_r: (61051, 433) | y_train_r: (61051,)\n",
      "X_test_r: (15263, 433) | y_test_r: (15263,)\n",
      "\n",
      "SENTTOT Stats in Train:\n",
      "count    61051.000000\n",
      "mean         0.000443\n",
      "std          1.001109\n",
      "min         -0.382653\n",
      "25%         -0.371663\n",
      "50%         -0.338525\n",
      "75%         -0.239110\n",
      "max          3.299299\n",
      "Name: SENTTOT, dtype: float64\n",
      "\n",
      "SENTTOT Stats in Test:\n",
      "count    15263.000000\n",
      "mean        -0.001771\n",
      "std          0.995616\n",
      "min         -0.382653\n",
      "25%         -0.371663\n",
      "50%         -0.338525\n",
      "75%         -0.235428\n",
      "max          3.299299\n",
      "Name: SENTTOT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- 4.2.2: SENTTOT as Regression Target ---\n",
    "print(\"\\n--- Regression Target: SENTTOT ---\")\n",
    "\n",
    "# a) No label encoding for numeric SENTTOT. We keep it as float/int\n",
    "#    If SENTTOT was read as object, ensure it's converted:\n",
    "final_df['SENTTOT'] = pd.to_numeric(final_df['SENTTOT'], errors='coerce')\n",
    "\n",
    "# b) Prepare X_regress & y_regress\n",
    "#    We exclude the columns used as classification target (DISPOSIT, DISPOSIT_ENCODED)\n",
    "#    to avoid confusion, but you can keep them if you want them as features.\n",
    "X_regress = final_df.drop(columns=['DISPOSIT', 'DISPOSIT_BINARY', 'SENTTOT'])\n",
    "y_regress = final_df['SENTTOT']\n",
    "\n",
    "# c) Train/Test Split for Regression\n",
    "#    No stratify needed for numeric target\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    X_regress,\n",
    "    y_regress,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nRegression splits:\")\n",
    "print(\"X_train_r:\", X_train_r.shape, \"| y_train_r:\", y_train_r.shape)\n",
    "print(\"X_test_r:\", X_test_r.shape,   \"| y_test_r:\", y_test_r.shape)\n",
    "\n",
    "# d) Basic Stats for the Regression Target\n",
    "print(\"\\nSENTTOT Stats in Train:\")\n",
    "print(y_train_r.describe())\n",
    "print(\"\\nSENTTOT Stats in Test:\")\n",
    "print(y_test_r.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUB-PHASE 4.3: BASELINE CLASSIFICATION (DISPOSIT) ===\n",
      "Train Accuracy (DISPOSIT): 0.694\n",
      "Test Accuracy  (DISPOSIT): 0.686\n",
      "\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.68      0.81     14897\n",
      "           1       0.05      0.74      0.10       366\n",
      "\n",
      "    accuracy                           0.69     15263\n",
      "   macro avg       0.52      0.71      0.46     15263\n",
      "weighted avg       0.97      0.69      0.79     15263\n",
      "\n",
      "\n",
      "Confusion Matrix (Test Set):\n",
      "[[10196  4701]\n",
      " [   95   271]]\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "#  SUB-PHASE 4.3: BASELINE \n",
    "#      CLASSIFICATION\n",
    "###############################\n",
    "print(\"\\n=== SUB-PHASE 4.3: BASELINE CLASSIFICATION (DISPOSIT) ===\")\n",
    "\n",
    "# 1. Baseline Model with Class Weights & Multinomial\n",
    "model_clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',  # Addresses class imbalance\n",
    "    solver='lbfgs'\n",
    ")\n",
    "model_clf.fit(X_train_c, y_train_c)\n",
    "\n",
    "# 2. Predictions & Evaluation\n",
    "y_pred_c_train = model_clf.predict(X_train_c)\n",
    "y_pred_c_test  = model_clf.predict(X_test_c)\n",
    "\n",
    "# 3. Metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "train_acc_c = accuracy_score(y_train_c, y_pred_c_train)\n",
    "test_acc_c  = accuracy_score(y_test_c, y_pred_c_test)\n",
    "\n",
    "print(f\"Train Accuracy (DISPOSIT): {train_acc_c:.3f}\")\n",
    "print(f\"Test Accuracy  (DISPOSIT): {test_acc_c:.3f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print(classification_report(\n",
    "    y_test_c, y_pred_c_test,\n",
    "    zero_division=0  # to avoid warnings, sets metrics to 0 instead of \"undefined\"\n",
    "))\n",
    "\n",
    "print(\"\\nConfusion Matrix (Test Set):\")\n",
    "print(confusion_matrix(y_test_c, y_pred_c_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUB-PHASE 4.4: BASELINE REGRESSION (SENTTOT) ===\n",
      "Train MSE (SENTTOT): 0.778, R2: 0.223\n",
      "Test  MSE (SENTTOT): 0.792, R2: 0.201\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "#   SUB-PHASE 4.4: BASELINE\n",
    "#      REGRESSION\n",
    "###############################\n",
    "print(\"\\n=== SUB-PHASE 4.4: BASELINE REGRESSION (SENTTOT) ===\")\n",
    "\n",
    "# 1. Baseline Model: Linear Regression\n",
    "model_reg = LinearRegression()\n",
    "model_reg.fit(X_train_r, y_train_r)\n",
    "\n",
    "# 2. Predictions & Evaluation\n",
    "y_pred_r_train = model_reg.predict(X_train_r)\n",
    "y_pred_r_test = model_reg.predict(X_test_r)\n",
    "\n",
    "# 3. Metrics: MSE, R2\n",
    "mse_train_r = mean_squared_error(y_train_r, y_pred_r_train)\n",
    "mse_test_r  = mean_squared_error(y_test_r,  y_pred_r_test)\n",
    "\n",
    "r2_train_r = r2_score(y_train_r, y_pred_r_train)\n",
    "r2_test_r  = r2_score(y_test_r,  y_pred_r_test)\n",
    "\n",
    "print(f\"Train MSE (SENTTOT): {mse_train_r:.3f}, R2: {r2_train_r:.3f}\")\n",
    "print(f\"Test  MSE (SENTTOT): {mse_test_r:.3f}, R2: {r2_test_r:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group-Level Accuracy for NEWRACE_Black = 1: 0.326\n",
      "Group-Level Accuracy for NEWRACE_Black = 0: 0.778\n",
      "\n",
      "Demographic Parity for 'DISPOSIT' = 1 (assuming label 1 is positive):\n",
      "Group: 0, Positive Rate for label=1: 0.226\n",
      "Group: 1, Positive Rate for label=1: 0.713\n",
      "\n",
      "Protected Group (1) TPR: 0.912, FPR: 0.703\n",
      "Non-Protected Group (0) TPR: 0.626, FPR: 0.219\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Fairness & Group-Level Metrics for Baseline Classification\n",
    "################################################################################\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# 1. Identify or Reconstruct Your Protected Attribute\n",
    "# Example: If 'NEWRACE_Black' is a one-hot column in X_test_c:\n",
    "protected_col = 'NEWRACE_Black'  # Adjust for your actual column\n",
    "\n",
    "# 2. Group-Level Accuracy\n",
    "def group_accuracy(X, y_true, y_pred, group_col, group_val):\n",
    "    idx = X[group_col] == group_val\n",
    "    # careful to align indices:\n",
    "    # if X_test_c was reindexed after train_test_split, ensure alignment\n",
    "    return accuracy_score(y_true[idx], y_pred[idx])\n",
    "\n",
    "acc_protected_1 = group_accuracy(X_test_c, y_test_c, y_pred_c_test, protected_col, 1)\n",
    "acc_protected_0 = group_accuracy(X_test_c, y_test_c, y_pred_c_test, protected_col, 0)\n",
    "\n",
    "print(f\"\\nGroup-Level Accuracy for {protected_col} = 1: {acc_protected_1:.3f}\")\n",
    "print(f\"Group-Level Accuracy for {protected_col} = 0: {acc_protected_0:.3f}\")\n",
    "\n",
    "# 3. Demographic Parity (Positive Prediction Rates)\n",
    "# This is relevant if you define \"positive\" = predicted class is 1\n",
    "# For a multi-class scenario, you might pick one class (e.g., \"Guilty\" if encoded as 1).\n",
    "def demographic_parity(X, y_pred, group_col, positive_label=1):\n",
    "    groups = [0,1]  # if your one-hot col is 0 or 1\n",
    "    for g in groups:\n",
    "        idx = X[group_col] == g\n",
    "        # Probability model assigned label=positive_label in that group\n",
    "        pos_rate = np.mean((y_pred[idx] == positive_label))\n",
    "        print(f\"Group: {g}, Positive Rate for label={positive_label}: {pos_rate:.3f}\")\n",
    "\n",
    "print(\"\\nDemographic Parity for 'DISPOSIT' = 1 (assuming label 1 is positive):\")\n",
    "demographic_parity(X_test_c, y_pred_c_test, protected_col, positive_label=1)\n",
    "\n",
    "# 4. TPR/FPR for each group (Binary scenario)\n",
    "# If your DISPOSIT is truly multi-class, you'd have to define a \"positive\" class vs. \"all else.\"\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def compute_tpr_fpr(y_true, y_pred, positive_label=1):\n",
    "    # For simplicity, treat everything that isn't 'positive_label' as 0\n",
    "    # This is only valid if your classification is effectively binary\n",
    "    y_true_bin = (y_true == positive_label).astype(int)\n",
    "    y_pred_bin = (y_pred == positive_label).astype(int)\n",
    "    \n",
    "    cm = confusion_matrix(y_true_bin, y_pred_bin, labels=[0, 1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "    return tpr, fpr\n",
    "\n",
    "# Example usage:\n",
    "tpr_1, fpr_1 = compute_tpr_fpr(\n",
    "    y_test_c[X_test_c[protected_col] == 1], \n",
    "    y_pred_c_test[X_test_c[protected_col] == 1],\n",
    "    positive_label=1\n",
    ")\n",
    "tpr_0, fpr_0 = compute_tpr_fpr(\n",
    "    y_test_c[X_test_c[protected_col] == 0], \n",
    "    y_pred_c_test[X_test_c[protected_col] == 0],\n",
    "    positive_label=1\n",
    ")\n",
    "\n",
    "print(f\"\\nProtected Group (1) TPR: {tpr_1:.3f}, FPR: {fpr_1:.3f}\")\n",
    "print(f\"Non-Protected Group (0) TPR: {tpr_0:.3f}, FPR: {fpr_0:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
