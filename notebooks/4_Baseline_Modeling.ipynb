{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "X_train: (59803, 439) y_train: (59803,)\n",
      "X_test: (14951, 439) y_test: (14951,)\n",
      "\n",
      "Train distribution of DISPOSIT_ENCODED:\n",
      "DISPOSIT_ENCODED\n",
      "0    0.974650\n",
      "2    0.023260\n",
      "3    0.000936\n",
      "4    0.000836\n",
      "1    0.000318\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test distribution of DISPOSIT_ENCODED:\n",
      "DISPOSIT_ENCODED\n",
      "0    0.974651\n",
      "2    0.023276\n",
      "3    0.000936\n",
      "4    0.000870\n",
      "1    0.000268\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Data is now ready for baseline modeling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/y3lhffxj6dl1rxzx2yw0441m0000gn/T/ipykernel_80232/813441550.py:13: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  original_df = pd.read_csv(\"../data/cleaned_data_phase3_unencoded_DISPOSIT.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load your fully encoded feature dataset + original DISPOSIT column\n",
    "#    (Ensure 'DISPOSIT' wasn't one-hot encoded in Phase 3 if it's truly the target)\n",
    "feature_file = \"../data/cleaned_data_phase3.csv\"\n",
    "encoded_features_df = pd.read_csv(feature_file)\n",
    "\n",
    "# You might need to merge or re-load DISPOSIT from your original or intermediate dataset\n",
    "# if you haven't included 'DISPOSIT' in 'cleaned_data_phase3_features.csv'.\n",
    "# Example:\n",
    "original_df = pd.read_csv(\"../data/cleaned_data_phase3_unencoded_DISPOSIT.csv\")\n",
    "final_df = encoded_features_df.join(original_df['DISPOSIT'])\n",
    "\n",
    "# 2. Encode the Target Variable DISPOSIT\n",
    "label_encoder = LabelEncoder()\n",
    "final_df['DISPOSIT_ENCODED'] = label_encoder.fit_transform(final_df['DISPOSIT'])\n",
    "\n",
    "# 3. Define Feature Matrix X and Target y\n",
    "X = final_df.drop(columns=['DISPOSIT', 'DISPOSIT_ENCODED'])\n",
    "y = final_df['DISPOSIT_ENCODED']\n",
    "\n",
    "# 4. Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)\n",
    "\n",
    "# 5. (Optional) Verify Class Distribution\n",
    "print(\"\\nTrain distribution of DISPOSIT_ENCODED:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest distribution of DISPOSIT_ENCODED:\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nData is now ready for baseline modeling.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline Logistic Regression ===\n",
      "Training Accuracy: 0.975\n",
      "Test Accuracy: 0.975\n",
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99     14572\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.50      0.01      0.01       348\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.97     14951\n",
      "   macro avg       0.29      0.20      0.20     14951\n",
      "weighted avg       0.96      0.97      0.96     14951\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/araj/.pyenv/versions/3.11.8/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/araj/.pyenv/versions/3.11.8/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/araj/.pyenv/versions/3.11.8/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the Final Dataset from Sub-Phase 4.2\n",
    "# Assuming you've done a train/test split and have X_train, X_test, y_train, y_test\n",
    "\n",
    "# 2. Select a Simple Classifier (Logistic Regression)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# 3. Train the Model & Evaluate Performance\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "print(\"=== Baseline Logistic Regression ===\")\n",
    "\n",
    "# Training Performance\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy: {train_acc:.3f}\")\n",
    "\n",
    "# Testing Performance\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n",
    "\n",
    "# Detailed Classification Report\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for NEWRACE_Black = 1: 0.9540191862388356\n",
      "Accuracy for NEWRACE_Black = 0: 0.9798792756539235\n",
      "Demographic Parity -> Group: False, Positive Rate: 0.000\n",
      "Demographic Parity -> Group: True, Positive Rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Identify Protected Attribute(s)\n",
    "# Example: 'NEWRACE_Hispanic' might be a column in X_test after get_dummies\n",
    "# Or you might re-merge the original 'NEWRACE' label if you dropped it.\n",
    "protected_col = 'NEWRACE_Black'  # Example column\n",
    "\n",
    "# 2. Predict on the Test Set\n",
    "y_pred_test = model.predict(X_test)  # Already done in Sub-Phase 4.3\n",
    "\n",
    "# 3. Compute Group-Level Metrics\n",
    "# We'll create a small function to compute accuracy for a given group\n",
    "def group_accuracy(X, y_true, y_pred, group_col, group_val):\n",
    "    idx = X[group_col] == group_val\n",
    "    return accuracy_score(y_true[idx], y_pred[idx])\n",
    "\n",
    "# Example: If your protected_col is binary (0 or 1)\n",
    "acc_group_1 = group_accuracy(X_test, y_test, y_pred_test, protected_col, 1)\n",
    "acc_group_0 = group_accuracy(X_test, y_test, y_pred_test, protected_col, 0)\n",
    "\n",
    "print(f\"\\nAccuracy for {protected_col} = 1:\", acc_group_1)\n",
    "print(f\"Accuracy for {protected_col} = 0:\", acc_group_0)\n",
    "\n",
    "# 4. (Optional) More Fairness Metrics\n",
    "# - Demographic Parity: Compare positive prediction rates (y_pred=1) across groups\n",
    "# - Equalized Odds: Compare TPR/FPR across groups\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def demographic_parity(X, y_pred, group_col):\n",
    "    # Probability of predicting \"positive\" for each group\n",
    "    groups = np.unique(X[group_col])\n",
    "    for g in groups:\n",
    "        idx = X[group_col] == g\n",
    "        pos_rate = np.mean(y_pred[idx])\n",
    "        print(f\"Demographic Parity -> Group: {g}, Positive Rate: {pos_rate:.3f}\")\n",
    "\n",
    "demographic_parity(X_test, y_pred_test, protected_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline Logistic Regression ===\n",
      "Training Accuracy: 0.975\n",
      "Test Accuracy: 0.975\n",
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99     14572\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.50      0.01      0.01       348\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.97     14951\n",
      "   macro avg       0.29      0.20      0.20     14951\n",
      "weighted avg       0.96      0.97      0.96     14951\n",
      "\n",
      "Precision (weighted): 0.962\n",
      "Recall (weighted): 0.975\n",
      "F1 Score (weighted): 0.962\n",
      "ROC AUC Score (OvR): 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/araj/.pyenv/versions/3.11.8/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/araj/.pyenv/versions/3.11.8/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/araj/.pyenv/versions/3.11.8/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/araj/.pyenv/versions/3.11.8/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 1. Train the Baseline Model (Logistic Regression)\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 2. Predict on Test Set\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# 3. Evaluate Performance Metrics\n",
    "print(\"=== Baseline Logistic Regression ===\")\n",
    "\n",
    "# Accuracy\n",
    "train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Training Accuracy: {train_acc:.3f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Precision, Recall, F1 Score with appropriate averaging\n",
    "precision = precision_score(y_test, y_pred_test, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_test, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "print(f\"Precision (weighted): {precision:.3f}\")\n",
    "print(f\"Recall (weighted): {recall:.3f}\")\n",
    "print(f\"F1 Score (weighted): {f1:.3f}\")\n",
    "\n",
    "# ROC AUC Score (only for binary classification)\n",
    "# If multiclass, use 'ovr' or 'ovo' strategies\n",
    "if len(np.unique(y)) == 2:\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_test)\n",
    "    print(f\"ROC AUC Score: {roc_auc:.3f}\")\n",
    "else:\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "    print(f\"ROC AUC Score (OvR): {roc_auc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Black Group TPR: 0.000, FPR: 0.000\n",
      "Non-Black Group TPR: 0.000, FPR: 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def compute_tpr_fpr(y_true, y_pred):\n",
    "    # Ensure the confusion matrix has both classes\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    \n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "    else:\n",
    "        # Handle cases with missing classes\n",
    "        tn, fp, fn, tp = 0, 0, 0, 0\n",
    "        if len(cm) == 1:\n",
    "            if cm.shape[0] == 1:\n",
    "                # Only one class present in y_true and y_pred\n",
    "                if y_true.iloc[0] == 0:\n",
    "                    tn = cm[0, 0]\n",
    "                else:\n",
    "                    tp = cm[0, 0]\n",
    "    \n",
    "    # Calculate TPR and FPR with checks to avoid division by zero\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    \n",
    "    return tpr, fpr\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'NEWRACE_Black' is one-hot encoded as 'NEWRACE_Black'\n",
    "protected_col = 'NEWRACE_Black'\n",
    "\n",
    "# Compute metrics for Black group\n",
    "tpr_black, fpr_black = compute_tpr_fpr(y_test[X_test[protected_col] == 1], y_pred_test[X_test[protected_col] == 1])\n",
    "\n",
    "# Compute metrics for Non-Black group\n",
    "tpr_non_black, fpr_non_black = compute_tpr_fpr(y_test[X_test[protected_col] == 0], y_pred_test[X_test[protected_col] == 0])\n",
    "\n",
    "print(f\"\\nBlack Group TPR: {tpr_black:.3f}, FPR: {fpr_black:.3f}\")\n",
    "print(f\"Non-Black Group TPR: {tpr_non_black:.3f}, FPR: {fpr_non_black:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
